"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || (function () {
    var ownKeys = function(o) {
        ownKeys = Object.getOwnPropertyNames || function (o) {
            var ar = [];
            for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;
            return ar;
        };
        return ownKeys(o);
    };
    return function (mod) {
        if (mod && mod.__esModule) return mod;
        var result = {};
        if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== "default") __createBinding(result, mod, k[i]);
        __setModuleDefault(result, mod);
        return result;
    };
})();
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.NativeAudioProcessor = void 0;
const fluent_ffmpeg_1 = __importDefault(require("fluent-ffmpeg"));
const ffmpeg_static_1 = __importDefault(require("ffmpeg-static"));
const path = __importStar(require("path"));
const fs = __importStar(require("fs"));
const os = __importStar(require("os"));
class NativeAudioProcessor {
    constructor() {
        this.isInitialized = false;
        this.MAX_SEGMENT_SIZE = 15 * 1024 * 1024; // 15MB
        this.OVERLAP_SECONDS = 5; // 5ç§’ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
        this.tempDir = path.join(os.tmpdir(), 'minutes-gen-' + Date.now());
        // FFmpegãƒ‘ã‚¹ã‚’è¨­å®š
        if (ffmpeg_static_1.default) {
            fluent_ffmpeg_1.default.setFfmpegPath(ffmpeg_static_1.default);
        }
    }
    /**
     * ãƒã‚¤ãƒ†ã‚£ãƒ–FFmpegã‚’åˆæœŸåŒ–
     */
    async initialize(onProgress) {
        if (this.isInitialized) {
            return;
        }
        onProgress?.({
            stage: 'transcribing',
            percentage: 5,
            currentTask: 'ï¿½ï¿½ éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’æº–å‚™ä¸­...',
            estimatedTimeRemaining: 0,
            logs: [{
                    id: Date.now().toString(),
                    timestamp: new Date(),
                    level: 'info',
                    message: 'ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™ã€‚'
                }],
            startedAt: new Date(),
        });
        try {
            // ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            await fs.promises.mkdir(this.tempDir, { recursive: true });
            // FFmpegã®å‹•ä½œç¢ºèª
            await this.testFFmpeg();
            this.isInitialized = true;
            onProgress?.({
                stage: 'transcribing',
                percentage: 15,
                currentTask: 'âœ… éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®æº–å‚™å®Œäº†',
                estimatedTimeRemaining: 0,
                logs: [{
                        id: Date.now().toString(),
                        timestamp: new Date(),
                        level: 'success',
                        message: 'ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚'
                    }],
                startedAt: new Date(),
            });
        }
        catch (error) {
            const errorMessage = `ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`;
            onProgress?.({
                stage: 'error',
                percentage: 100,
                currentTask: 'âŒ éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼',
                estimatedTimeRemaining: 0,
                logs: [{
                        id: Date.now().toString(),
                        timestamp: new Date(),
                        level: 'error',
                        message: errorMessage
                    }],
                startedAt: new Date(),
            });
            throw new Error(errorMessage);
        }
    }
    /**
     * FFmpegã®å‹•ä½œç¢ºèª
     */
    async testFFmpeg() {
        return new Promise((resolve, reject) => {
            (0, fluent_ffmpeg_1.default)()
                .input('color=black:size=1x1:duration=0.1')
                .inputFormat('lavfi')
                .output(path.join(this.tempDir, 'test.mp3'))
                .audioCodec('mp3')
                .on('end', () => {
                fs.promises.unlink(path.join(this.tempDir, 'test.mp3')).catch(() => { });
                resolve();
            })
                .on('error', (error) => {
                reject(new Error(`FFmpegå‹•ä½œç¢ºèªå¤±æ•—: ${error.message}`));
            })
                .run();
        });
    }
    /**
     * å¤§å®¹é‡éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²
     */
    async processLargeAudioFile(inputPath, segmentDurationSeconds = 600, onProgress) {
        await this.initialize(onProgress);
        try {
            onProgress?.({
                stage: 'transcribing',
                percentage: 20,
                currentTask: 'ğŸ“Š éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æä¸­...',
                estimatedTimeRemaining: 0,
                logs: [{
                        id: Date.now().toString(),
                        timestamp: new Date(),
                        level: 'info',
                        message: 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã„ã¾ã™...'
                    }],
                startedAt: new Date(),
            });
            // éŸ³å£°ã®é•·ã•ã‚’å–å¾—
            const duration = await this.getAudioDuration(inputPath);
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
            const fileSizeBytes = (await fs.promises.stat(inputPath)).size;
            // åœ§ç¸®ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
            let workingFile = inputPath;
            if (fileSizeBytes > this.MAX_SEGMENT_SIZE) {
                workingFile = await this.compressAudio(inputPath, onProgress);
            }
            // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå¢ƒç•Œã‚’è¨ˆç®—
            const segments = this.calculateSegments(duration, segmentDurationSeconds);
            onProgress?.({
                stage: 'transcribing',
                percentage: 50,
                currentTask: `ğŸ“ ${Math.floor(duration / 60)}åˆ†ã®éŸ³å£°ã‚’${segments.length}å€‹ã«åˆ†å‰²æº–å‚™ä¸­...`,
                estimatedTimeRemaining: 0,
                logs: [{
                        id: Date.now().toString(),
                        timestamp: new Date(),
                        level: 'info',
                        message: `éŸ³å£°ã‚’${segments.length}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¾ã™ã€‚`
                    }],
                startedAt: new Date(),
            });
            const audioSegments = [];
            for (let i = 0; i < segments.length; i++) {
                const segment = segments[i];
                onProgress?.({
                    stage: 'transcribing',
                    percentage: 50 + Math.round((i / segments.length) * 40),
                    currentTask: `âœ‚ï¸ éŸ³å£°ã‚’${segments.length}å€‹ã«åˆ†å‰²ä¸­ (${i + 1}/${segments.length})`,
                    estimatedTimeRemaining: 0,
                    logs: [{
                            id: Date.now().toString(),
                            timestamp: new Date(),
                            level: 'info',
                            message: `ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ${i + 1}: ${segment.start.toFixed(1)}s - ${segment.end.toFixed(1)}s`
                        }],
                    startedAt: new Date(),
                });
                const segmentPath = path.join(this.tempDir, `segment_${i.toString().padStart(3, '0')}.wav`);
                await this.extractSegment(workingFile, segmentPath, segment, onProgress, i + 1, segments.length);
                // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’Blobã¨ã—ã¦èª­ã¿è¾¼ã¿
                const segmentData = await fs.promises.readFile(segmentPath);
                const blob = new Blob([segmentData], { type: 'audio/wav' });
                const segmentDuration = await this.getAudioDuration(segmentPath);
                audioSegments.push({
                    blob,
                    name: `segment_${i.toString().padStart(3, '0')}.wav`,
                    duration: segmentDuration,
                    startTime: segment.start,
                    endTime: segment.end,
                });
                // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                await fs.promises.unlink(segmentPath);
            }
            // åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ãŸå ´åˆã¯å‰Šé™¤
            if (workingFile !== inputPath) {
                await fs.promises.unlink(workingFile);
            }
            onProgress?.({
                stage: 'transcribing',
                percentage: 95,
                currentTask: 'âœ… éŸ³å£°åˆ†å‰²ã®æº–å‚™å®Œäº†',
                estimatedTimeRemaining: 0,
                logs: [{
                        id: Date.now().toString(),
                        timestamp: new Date(),
                        level: 'success',
                        message: `åˆè¨ˆ ${audioSegments.length} å€‹ã®éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚`
                    }],
                startedAt: new Date(),
            });
            return audioSegments;
        }
        catch (error) {
            const errorMessage = `éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`;
            onProgress?.({
                stage: 'error',
                percentage: 100,
                currentTask: 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼',
                estimatedTimeRemaining: 0,
                logs: [{
                        id: Date.now().toString(),
                        timestamp: new Date(),
                        level: 'error',
                        message: errorMessage
                    }],
                startedAt: new Date(),
            });
            throw new Error(errorMessage);
        }
    }
    /**
     * éŸ³å£°ã‚’åœ§ç¸®
     */
    async compressAudio(inputPath, onProgress) {
        const outputPath = path.join(this.tempDir, 'compressed_audio.mp3');
        onProgress?.({
            stage: 'transcribing',
            percentage: 30,
            currentTask: 'ğŸ—œï¸ éŸ³å£°ã‚’åœ§ç¸®ä¸­...',
            estimatedTimeRemaining: 0,
            logs: [{
                    id: Date.now().toString(),
                    timestamp: new Date(),
                    level: 'info',
                    message: 'éŸ³å£°åœ§ç¸®ã‚’é–‹å§‹ã—ã¾ã™...'
                }],
            startedAt: new Date(),
        });
        return new Promise((resolve, reject) => {
            (0, fluent_ffmpeg_1.default)(inputPath)
                .audioCodec('mp3')
                .audioBitrate('128k')
                .audioFrequency(44100)
                .audioChannels(1)
                .format('mp3')
                .output(outputPath)
                .on('progress', (progressData) => {
                // FFmpegã®è©³ç´°ãªé€²æ—æƒ…å ±ã‚’å–å¾—
                const currentPercent = Math.min(35, 30 + Math.round((progressData.percent || 0) * 0.1));
                onProgress?.({
                    stage: 'transcribing',
                    percentage: currentPercent,
                    currentTask: 'ğŸ—œï¸ éŸ³å£°ã‚’åœ§ç¸®ä¸­...',
                    estimatedTimeRemaining: 0,
                    logs: [{
                            id: Date.now().toString(),
                            timestamp: new Date(),
                            level: 'info',
                            message: `éŸ³å£°åœ§ç¸®: ${progressData.timemark || 'ä¸æ˜'} å‡¦ç†æ¸ˆã¿ (${progressData.currentFps?.toFixed(1) || 'ä¸æ˜'}fps, ${progressData.currentKbps?.toFixed(0) || 'ä¸æ˜'}kbps)`
                        }],
                    startedAt: new Date(),
                    processingDetails: {
                        frames: progressData.frames || 0,
                        currentFps: progressData.currentFps || 0,
                        currentKbps: progressData.currentKbps || 0,
                        targetSize: progressData.targetSize || 0,
                        timemark: progressData.timemark || '0:00:00.00'
                    }
                });
            })
                .on('end', () => {
                onProgress?.({
                    stage: 'transcribing',
                    percentage: 40,
                    currentTask: 'ğŸ—œï¸ éŸ³å£°åœ§ç¸®å®Œäº†',
                    estimatedTimeRemaining: 0,
                    logs: [{
                            id: Date.now().toString(),
                            timestamp: new Date(),
                            level: 'success',
                            message: 'éŸ³å£°åœ§ç¸®ãŒå®Œäº†ã—ã¾ã—ãŸã€‚'
                        }],
                    startedAt: new Date(),
                });
                resolve(outputPath);
            })
                .on('error', (error) => {
                reject(new Error(`éŸ³å£°åœ§ç¸®ã‚¨ãƒ©ãƒ¼: ${error.message}`));
            })
                .run();
        });
    }
    /**
     * éŸ³å£°ã®é•·ã•ã‚’å–å¾—
     */
    async getAudioDuration(filePath) {
        return new Promise((resolve, reject) => {
            fluent_ffmpeg_1.default.ffprobe(filePath, (err, metadata) => {
                if (err) {
                    reject(new Error(`éŸ³å£°é•·ã•å–å¾—ã‚¨ãƒ©ãƒ¼: ${err.message}`));
                }
                else {
                    resolve(metadata.format.duration || 0);
                }
            });
        });
    }
    /**
     * ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå¢ƒç•Œã‚’è¨ˆç®—
     */
    calculateSegments(totalDuration, segmentDuration) {
        const segments = [];
        let currentStart = 0;
        while (currentStart < totalDuration) {
            const currentEnd = Math.min(currentStart + segmentDuration, totalDuration);
            segments.push({
                start: currentStart,
                end: currentEnd,
                overlapStart: currentStart > 0 ? currentStart - this.OVERLAP_SECONDS : currentStart,
                overlapEnd: currentEnd < totalDuration ? currentEnd + this.OVERLAP_SECONDS : currentEnd,
            });
            currentStart = currentEnd;
        }
        return segments;
    }
    /**
     * ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡º
     */
    async extractSegment(inputPath, outputPath, segment, onProgress, currentSegmentIndex = 0, totalSegments = 0) {
        return new Promise((resolve, reject) => {
            (0, fluent_ffmpeg_1.default)(inputPath)
                .seekInput(segment.start)
                .duration(segment.end - segment.start)
                .audioCodec('pcm_s16le')
                .audioFrequency(44100)
                .audioChannels(1)
                .format('wav')
                .output(outputPath)
                .on('end', () => resolve())
                .on('error', (error) => reject(new Error(`ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: ${error.message}`)))
                .on('progress', (progressData) => {
                // FFmpegã®è©³ç´°ãªé€²æ—æƒ…å ±ã‚’å–å¾—
                const currentPercent = Math.min(35, 30 + Math.round((progressData.percent || 0) * 0.1));
                onProgress?.({
                    stage: 'transcribing',
                    percentage: currentPercent,
                    currentTask: `âœ‚ï¸ éŸ³å£°ã‚’${totalSegments}å€‹ã«åˆ†å‰²ä¸­ (${currentSegmentIndex}/${totalSegments})`,
                    estimatedTimeRemaining: 0,
                    logs: [{
                            id: Date.now().toString(),
                            timestamp: new Date(),
                            level: 'info',
                            message: `ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ${currentSegmentIndex}: ${progressData.timemark || 'ä¸æ˜'} å‡¦ç†æ¸ˆã¿ (${progressData.currentFps?.toFixed(1) || 'ä¸æ˜'}fps, ${progressData.currentKbps?.toFixed(0) || 'ä¸æ˜'}kbps)`
                        }],
                    startedAt: new Date(),
                    processingDetails: {
                        frames: progressData.frames || 0,
                        currentFps: progressData.currentFps || 0,
                        currentKbps: progressData.currentKbps || 0,
                        targetSize: progressData.targetSize || 0,
                        timemark: progressData.timemark || '0:00:00.00'
                    }
                });
            })
                .run();
        });
    }
    /**
     * Blobã‹ã‚‰Audioã‚’ä½œæˆã—ã¦é•·ã•ã‚’å–å¾—
     */
    async getAudioDurationFromBlob(blob) {
        // Main processã§ã¯ç›´æ¥çš„ãªBlobå‡¦ç†ã¯å›°é›£ãªãŸã‚ã€
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€šã—ã¦å‡¦ç†ã™ã‚‹
        const tempPath = path.join(this.tempDir, 'temp_audio_' + Date.now());
        const buffer = Buffer.from(await blob.arrayBuffer());
        await fs.promises.writeFile(tempPath, buffer);
        try {
            const duration = await this.getAudioDuration(tempPath);
            await fs.promises.unlink(tempPath);
            return duration;
        }
        catch (error) {
            await fs.promises.unlink(tempPath).catch(() => { });
            throw error;
        }
    }
    /**
     * ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
     */
    async cleanup() {
        try {
            if (fs.existsSync(this.tempDir)) {
                await fs.promises.rmdir(this.tempDir, { recursive: true });
            }
            this.isInitialized = false;
        }
        catch (error) {
            console.warn('ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼:', error);
        }
    }
}
exports.NativeAudioProcessor = NativeAudioProcessor;
