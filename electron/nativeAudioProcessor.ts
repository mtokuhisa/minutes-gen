import ffmpeg from 'fluent-ffmpeg';
import ffmpegPath from 'ffmpeg-static';
import * as path from 'path';
import * as fs from 'fs';
import * as os from 'os';

// å‹å®šç¾©
interface AudioSegment {
  blob: Blob;
  name: string;
  duration: number;
  startTime: number;
  endTime: number;
}

interface SegmentBoundary {
  start: number;
  end: number;
  overlapStart?: number;
  overlapEnd?: number;
}

interface ProcessingProgress {
  stage: 'transcribing' | 'error';
  percentage: number;
  currentTask: string;
  estimatedTimeRemaining: number;
  logs: LogEntry[];
  startedAt: Date;
  processingDetails?: {
    frames: number;
    currentFps: number;
    currentKbps: number;
    targetSize: number;
    timemark: string;
  };
}

interface LogEntry {
  id: string;
  timestamp: Date;
  level: 'info' | 'warning' | 'error' | 'success';
  message: string;
}

export class NativeAudioProcessor {
  private tempDir: string;
  private isInitialized: boolean = false;
  private readonly MAX_SEGMENT_SIZE = 15 * 1024 * 1024; // 15MB
  private readonly OVERLAP_SECONDS = 5; // 5ç§’ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—

  constructor() {
    this.tempDir = path.join(os.tmpdir(), 'minutes-gen-' + Date.now());
    
    // FFmpegãƒ‘ã‚¹ã‚’è¨­å®š
    if (ffmpegPath) {
      ffmpeg.setFfmpegPath(ffmpegPath);
    }
  }

  /**
   * ãƒã‚¤ãƒ†ã‚£ãƒ–FFmpegã‚’åˆæœŸåŒ–
   */
  async initialize(onProgress?: (progress: ProcessingProgress) => void): Promise<void> {
    if (this.isInitialized) {
      return;
    }

    onProgress?.({
      stage: 'transcribing',
      percentage: 5,
      currentTask: 'ï¿½ï¿½ éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’æº–å‚™ä¸­...',
      estimatedTimeRemaining: 0,
      logs: [{ 
        id: Date.now().toString(), 
        timestamp: new Date(), 
        level: 'info', 
        message: 'ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™ã€‚' 
      }],
      startedAt: new Date(),
    });

    try {
      // ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
      await fs.promises.mkdir(this.tempDir, { recursive: true });
      
      // FFmpegã®å‹•ä½œç¢ºèª
      await this.testFFmpeg();
      
      this.isInitialized = true;
      
      onProgress?.({
        stage: 'transcribing',
        percentage: 15,
        currentTask: 'âœ… éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®æº–å‚™å®Œäº†',
        estimatedTimeRemaining: 0,
        logs: [{ 
          id: Date.now().toString(), 
          timestamp: new Date(), 
          level: 'success', 
          message: 'ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚' 
        }],
        startedAt: new Date(),
      });
    } catch (error) {
      const errorMessage = `ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`;
      onProgress?.({
        stage: 'error',
        percentage: 100,
        currentTask: 'âŒ éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼',
        estimatedTimeRemaining: 0,
        logs: [{ 
          id: Date.now().toString(), 
          timestamp: new Date(), 
          level: 'error', 
          message: errorMessage 
        }],
        startedAt: new Date(),
      });
      throw new Error(errorMessage);
    }
  }

  /**
   * FFmpegã®å‹•ä½œç¢ºèª
   */
  private async testFFmpeg(): Promise<void> {
    return new Promise((resolve, reject) => {
      ffmpeg()
        .input('color=black:size=1x1:duration=0.1')
        .inputFormat('lavfi')
        .output(path.join(this.tempDir, 'test.mp3'))
        .audioCodec('mp3')
        .on('end', () => {
          fs.promises.unlink(path.join(this.tempDir, 'test.mp3')).catch(() => {});
          resolve();
        })
        .on('error', (error: Error) => {
          reject(new Error(`FFmpegå‹•ä½œç¢ºèªå¤±æ•—: ${error.message}`));
        })
        .run();
    });
  }

  /**
   * å¤§å®¹é‡éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²
   */
  async processLargeAudioFile(
    inputPath: string,
    segmentDurationSeconds: number = 600,
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<AudioSegment[]> {
    await this.initialize(onProgress);

    try {
      onProgress?.({
        stage: 'transcribing',
        percentage: 20,
        currentTask: 'ğŸ“Š éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æä¸­...',
        estimatedTimeRemaining: 0,
        logs: [{ 
          id: Date.now().toString(), 
          timestamp: new Date(), 
          level: 'info', 
          message: 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã„ã¾ã™...' 
        }],
        startedAt: new Date(),
      });

      // éŸ³å£°ã®é•·ã•ã‚’å–å¾—
      const duration = await this.getAudioDuration(inputPath);
      
      // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
      const fileSizeBytes = (await fs.promises.stat(inputPath)).size;
      
      // åœ§ç¸®ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
      let workingFile = inputPath;
      if (fileSizeBytes > this.MAX_SEGMENT_SIZE) {
        workingFile = await this.compressAudio(inputPath, onProgress);
      }

      // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå¢ƒç•Œã‚’è¨ˆç®—
      const segments = this.calculateSegments(duration, segmentDurationSeconds);
      
      onProgress?.({
        stage: 'transcribing',
        percentage: 50,
        currentTask: `ğŸ“ ${Math.floor(duration / 60)}åˆ†ã®éŸ³å£°ã‚’${segments.length}å€‹ã«åˆ†å‰²æº–å‚™ä¸­...`,
        estimatedTimeRemaining: 0,
        logs: [{ 
          id: Date.now().toString(), 
          timestamp: new Date(), 
          level: 'info', 
          message: `éŸ³å£°ã‚’${segments.length}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¾ã™ã€‚` 
        }],
        startedAt: new Date(),
      });

      const audioSegments: AudioSegment[] = [];
      
      for (let i = 0; i < segments.length; i++) {
        const segment = segments[i];
        
        onProgress?.({
          stage: 'transcribing',
          percentage: 50 + Math.round((i / segments.length) * 40),
          currentTask: `âœ‚ï¸ éŸ³å£°ã‚’${segments.length}å€‹ã«åˆ†å‰²ä¸­ (${i + 1}/${segments.length})`,
          estimatedTimeRemaining: 0,
          logs: [{ 
            id: Date.now().toString(), 
            timestamp: new Date(), 
            level: 'info', 
            message: `ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ${i + 1}: ${segment.start.toFixed(1)}s - ${segment.end.toFixed(1)}s` 
          }],
          startedAt: new Date(),
        });

        const segmentPath = path.join(this.tempDir, `segment_${i.toString().padStart(3, '0')}.wav`);
        await this.extractSegment(workingFile, segmentPath, segment, onProgress, i + 1, segments.length);
        
        // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’Blobã¨ã—ã¦èª­ã¿è¾¼ã¿
        const segmentData = await fs.promises.readFile(segmentPath);
        const blob = new Blob([segmentData], { type: 'audio/wav' });
        
        const segmentDuration = await this.getAudioDuration(segmentPath);
        
        audioSegments.push({
          blob,
          name: `segment_${i.toString().padStart(3, '0')}.wav`,
          duration: segmentDuration,
          startTime: segment.start,
          endTime: segment.end,
        });

        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        await fs.promises.unlink(segmentPath);
      }

      // åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ãŸå ´åˆã¯å‰Šé™¤
      if (workingFile !== inputPath) {
        await fs.promises.unlink(workingFile);
      }

      onProgress?.({
        stage: 'transcribing',
        percentage: 95,
        currentTask: 'âœ… éŸ³å£°åˆ†å‰²ã®æº–å‚™å®Œäº†',
        estimatedTimeRemaining: 0,
        logs: [{ 
          id: Date.now().toString(), 
          timestamp: new Date(), 
          level: 'success', 
          message: `åˆè¨ˆ ${audioSegments.length} å€‹ã®éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚` 
        }],
        startedAt: new Date(),
      });

      return audioSegments;
    } catch (error) {
      const errorMessage = `éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`;
      onProgress?.({
        stage: 'error',
        percentage: 100,
        currentTask: 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼',
        estimatedTimeRemaining: 0,
        logs: [{ 
          id: Date.now().toString(), 
          timestamp: new Date(), 
          level: 'error', 
          message: errorMessage 
        }],
        startedAt: new Date(),
      });
      throw new Error(errorMessage);
    }
  }

  /**
   * éŸ³å£°ã‚’åœ§ç¸®
   */
  private async compressAudio(inputPath: string, onProgress?: (progress: ProcessingProgress) => void): Promise<string> {
    const outputPath = path.join(this.tempDir, 'compressed_audio.mp3');
    
    onProgress?.({
      stage: 'transcribing',
      percentage: 30,
      currentTask: 'ğŸ—œï¸ éŸ³å£°ã‚’åœ§ç¸®ä¸­...',
      estimatedTimeRemaining: 0,
      logs: [{ 
        id: Date.now().toString(), 
        timestamp: new Date(), 
        level: 'info', 
        message: 'éŸ³å£°åœ§ç¸®ã‚’é–‹å§‹ã—ã¾ã™...' 
      }],
      startedAt: new Date(),
    });

    return new Promise((resolve, reject) => {
      ffmpeg(inputPath)
        .audioCodec('mp3')
        .audioBitrate('128k')
        .audioFrequency(44100)
        .audioChannels(1)
        .format('mp3')
        .output(outputPath)
        .on('progress', (progressData) => {
          // FFmpegã®è©³ç´°ãªé€²æ—æƒ…å ±ã‚’å–å¾—
          const currentPercent = Math.min(35, 30 + Math.round((progressData.percent || 0) * 0.1));
          
          onProgress?.({
            stage: 'transcribing',
            percentage: currentPercent,
            currentTask: 'ğŸ—œï¸ éŸ³å£°ã‚’åœ§ç¸®ä¸­...',
            estimatedTimeRemaining: 0,
            logs: [{ 
              id: Date.now().toString(), 
              timestamp: new Date(), 
              level: 'info', 
              message: `éŸ³å£°åœ§ç¸®: ${progressData.timemark || 'ä¸æ˜'} å‡¦ç†æ¸ˆã¿ (${progressData.currentFps?.toFixed(1) || 'ä¸æ˜'}fps, ${progressData.currentKbps?.toFixed(0) || 'ä¸æ˜'}kbps)` 
            }],
            startedAt: new Date(),
            processingDetails: {
              frames: progressData.frames || 0,
              currentFps: progressData.currentFps || 0,
              currentKbps: progressData.currentKbps || 0,
              targetSize: progressData.targetSize || 0,
              timemark: progressData.timemark || '0:00:00.00'
            }
          });
        })
        .on('end', () => {
          onProgress?.({
            stage: 'transcribing',
            percentage: 40,
            currentTask: 'ğŸ—œï¸ éŸ³å£°åœ§ç¸®å®Œäº†',
            estimatedTimeRemaining: 0,
            logs: [{ 
              id: Date.now().toString(), 
              timestamp: new Date(), 
              level: 'success', 
              message: 'éŸ³å£°åœ§ç¸®ãŒå®Œäº†ã—ã¾ã—ãŸã€‚' 
            }],
            startedAt: new Date(),
          });
          resolve(outputPath);
        })
        .on('error', (error: Error) => {
          reject(new Error(`éŸ³å£°åœ§ç¸®ã‚¨ãƒ©ãƒ¼: ${error.message}`));
        })
        .run();
    });
  }

  /**
   * éŸ³å£°ã®é•·ã•ã‚’å–å¾—
   */
  private async getAudioDuration(filePath: string): Promise<number> {
    return new Promise((resolve, reject) => {
      ffmpeg.ffprobe(filePath, (err, metadata) => {
        if (err) {
          reject(new Error(`éŸ³å£°é•·ã•å–å¾—ã‚¨ãƒ©ãƒ¼: ${err.message}`));
        } else {
          resolve(metadata.format.duration || 0);
        }
      });
    });
  }

  /**
   * ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå¢ƒç•Œã‚’è¨ˆç®—
   */
  private calculateSegments(totalDuration: number, segmentDuration: number): SegmentBoundary[] {
    const segments: SegmentBoundary[] = [];
    let currentStart = 0;

    while (currentStart < totalDuration) {
      const currentEnd = Math.min(currentStart + segmentDuration, totalDuration);
      
      segments.push({
        start: currentStart,
        end: currentEnd,
        overlapStart: currentStart > 0 ? currentStart - this.OVERLAP_SECONDS : currentStart,
        overlapEnd: currentEnd < totalDuration ? currentEnd + this.OVERLAP_SECONDS : currentEnd,
      });

      currentStart = currentEnd;
    }

    return segments;
  }

  /**
   * ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡º
   */
  private async extractSegment(inputPath: string, outputPath: string, segment: SegmentBoundary, onProgress?: (progress: ProcessingProgress) => void, currentSegmentIndex: number = 0, totalSegments: number = 0): Promise<void> {
    return new Promise((resolve, reject) => {
      ffmpeg(inputPath)
        .seekInput(segment.start)
        .duration(segment.end - segment.start)
        .audioCodec('pcm_s16le')
        .audioFrequency(44100)
        .audioChannels(1)
        .format('wav')
        .output(outputPath)
        .on('end', () => resolve())
        .on('error', (error: Error) => reject(new Error(`ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: ${error.message}`)))
        .on('progress', (progressData) => {
          // FFmpegã®è©³ç´°ãªé€²æ—æƒ…å ±ã‚’å–å¾—
          const currentPercent = Math.min(35, 30 + Math.round((progressData.percent || 0) * 0.1));
          
          onProgress?.({
            stage: 'transcribing',
            percentage: currentPercent,
            currentTask: `âœ‚ï¸ éŸ³å£°ã‚’${totalSegments}å€‹ã«åˆ†å‰²ä¸­ (${currentSegmentIndex}/${totalSegments})`,
            estimatedTimeRemaining: 0,
            logs: [{ 
              id: Date.now().toString(), 
              timestamp: new Date(), 
              level: 'info', 
              message: `ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ${currentSegmentIndex}: ${progressData.timemark || 'ä¸æ˜'} å‡¦ç†æ¸ˆã¿ (${progressData.currentFps?.toFixed(1) || 'ä¸æ˜'}fps, ${progressData.currentKbps?.toFixed(0) || 'ä¸æ˜'}kbps)` 
            }],
            startedAt: new Date(),
            processingDetails: {
              frames: progressData.frames || 0,
              currentFps: progressData.currentFps || 0,
              currentKbps: progressData.currentKbps || 0,
              targetSize: progressData.targetSize || 0,
              timemark: progressData.timemark || '0:00:00.00'
            }
          });
        })
        .run();
    });
  }

  /**
   * Blobã‹ã‚‰Audioã‚’ä½œæˆã—ã¦é•·ã•ã‚’å–å¾—
   */
  async getAudioDurationFromBlob(blob: Blob): Promise<number> {
    // Main processã§ã¯ç›´æ¥çš„ãªBlobå‡¦ç†ã¯å›°é›£ãªãŸã‚ã€
    // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€šã—ã¦å‡¦ç†ã™ã‚‹
    const tempPath = path.join(this.tempDir, 'temp_audio_' + Date.now());
    const buffer = Buffer.from(await blob.arrayBuffer());
    await fs.promises.writeFile(tempPath, buffer);
    
    try {
      const duration = await this.getAudioDuration(tempPath);
      await fs.promises.unlink(tempPath);
      return duration;
    } catch (error) {
      await fs.promises.unlink(tempPath).catch(() => {});
      throw error;
    }
  }

  /**
   * ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
   */
  async cleanup(): Promise<void> {
    try {
      if (fs.existsSync(this.tempDir)) {
        await fs.promises.rmdir(this.tempDir, { recursive: true });
      }
      this.isInitialized = false;
    } catch (error) {
      console.warn('ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼:', error);
    }
  }
} 